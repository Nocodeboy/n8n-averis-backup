{
  "createdAt": "2025-04-29T10:14:31.445Z",
  "updatedAt": "2025-04-29T13:45:17.550Z",
  "id": "kvYjuvmWMiwpxNQZ",
  "name": "RAG Sem√°ntico",
  "active": false,
  "nodes": [
    {
      "parameters": {
        "jsCode": "// ‚úÖ Paso 1: Obtener el texto desde la variable de entrada JSON.\n// Si no existe, usamos un string vac√≠o para evitar errores.\nconst text = $json.text || '';\n\n// ‚úÖ Paso 2: Limpiar el texto para facilitar el procesamiento.\n// - normalize(\"NFD\"): separa letras y tildes (ej. \"√°\" -> \"a\" + tilde).\n// - replace: elimina saltos de l√≠nea (\\n), retornos (\\r), tabulaciones (\\t) y espacios duplicados.\nconst cleanText = text.normalize(\"NFD\")\n  .replace(/[\\n\\r\\t]+/g, ' ')\n  .replace(/\\s{2,}/g, ' ');\n\n// ‚úÖ Paso 3: Dividir el texto en frases.\n// Usamos una expresi√≥n regular que detecta final de frase (., ?, ! seguidos de espacio).\nconst sentences = cleanText.split(/(?<=[.?!])\\s+/);\n\n// ‚úÖ Paso 4: Preparar variables\nconst chunks = [];         // Aqu√≠ guardaremos los fragmentos resultantes\nlet currentChunk = [];     // Acumula frases hasta llegar al l√≠mite\nlet charCursor = 0;        // Nos ayuda a encontrar la posici√≥n exacta del fragmento en el texto original\n\n// ‚úÖ Paso 5: Recorrer todas las frases una a una\nfor (let i = 0; i < sentences.length; i++) {\n  const sentence = sentences[i];\n  currentChunk.push(sentence); // A√±adir frase al bloque actual\n\n  // Si el bloque tiene al menos 3 frases y supera los 500 caracteres, lo cortamos aqu√≠\n  if (currentChunk.length >= 3 || currentChunk.join(\" \").length > 500) {\n    const chunkText = currentChunk.join(\" \");           // Convertimos el bloque en texto completo\n    const searchText = chunkText.slice(0, 30);          // Cogemos los primeros 30 caracteres para buscarlo en el texto original\n    const matchPos = cleanText.indexOf(searchText, charCursor); // Buscamos el fragmento en el texto original desde la √∫ltima posici√≥n\n\n    const startIndex = matchPos > -1 ? matchPos : null; // Si lo encontramos, guardamos la posici√≥n\n\n    // Guardamos el bloque en la lista de chunks\n    chunks.push({\n      chunk: chunkText,\n      startIndex: startIndex,\n    });\n\n    // Avanzamos el cursor si encontramos la posici√≥n\n    if (matchPos > -1) charCursor = matchPos + chunkText.length;\n\n    // Reseteamos el bloque actual para seguir con el siguiente\n    currentChunk = [];\n  }\n}\n\n// ‚úÖ Paso 6: Guardar el √∫ltimo fragmento que haya quedado pendiente\nif (currentChunk.length) {\n  const chunkText = currentChunk.join(\" \");\n  const searchText = chunkText.slice(0, 30);\n  const matchPos = cleanText.indexOf(searchText, charCursor);\n  const startIndex = matchPos > -1 ? matchPos : null;\n\n  chunks.push({\n    chunk: chunkText,\n    startIndex: startIndex,\n  });\n}\n\n// ‚úÖ Paso 7: Devolver los resultados en el formato que espera n8n\n// Cada fragmento se envuelve dentro de un objeto { json: ... }\nreturn chunks.map(c => ({ json: c }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1740,
        160
      ],
      "id": "37e86bfb-b8e0-461f-91c5-4c48aecd938f",
      "name": "Semantic Chunker"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://aasupabaseaa.vps.rubikmarketing.com.co/rest/v1/documents_RAG_Semantico",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Prefer",
              "value": "return=representation"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"content\": \"{{ $('Code').item.json.chunk.replaceAll('\\\"','') }}\",\n  \"metadata\": {\n    \"file_name\": \"{{ $('Google Drive1').item.json.message.content.title.replaceAll('\\\"','') }}\",\n    \"title\": \"{{ $('Code').item.json.originalInput.message.content.title }}\",\n    \"section\": \"{{ $('Code').item.json.originalInput.message.content.section }}\",\n    \"subsection\": \"{{ $('Code').item.json.originalInput.message.content.subsection }}\",\n    \"pages\": \"{{ $('Extract from File1').item.json.numpages }}\",\n    \"id_file\": \"{{ $('Google Drive').item.json.id }}\"\n  },\n  \"embedding\": {{ JSON.stringify($json.data[0].embedding) }}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3080,
        240
      ],
      "id": "5c390d7f-3fb4-4dde-b0b3-fbefcd27f15b",
      "name": "HTTP Request2",
      "credentials": {
        "supabaseApi": {
          "id": "CfhQFyBpZqxDZXe2",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        1960,
        160
      ],
      "id": "cbb7cdac-466c-4e89-893d-32af129dfe9c",
      "name": "Loop Over Items"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        60,
        160
      ],
      "id": "77c7bfbc-ca04-43bd-abfc-8292d3b9fb9a",
      "name": "When clicking ‚ÄòTest workflow‚Äô"
    },
    {
      "parameters": {
        "operation": "download",
        "fileId": {
          "__rl": true,
          "value": "={{ $json.id }}",
          "mode": "id"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        600,
        160
      ],
      "id": "000a3a74-aa23-45c4-84af-d9c6234d3d19",
      "name": "Google Drive",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "CmyDLQoxYdr0aKik",
          "name": "Google Daniel Averis"
        }
      }
    },
    {
      "parameters": {
        "operation": "pdf",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        860,
        160
      ],
      "id": "a89e6169-4be2-41a9-b9a6-9127a3e6c9af",
      "name": "Extract from File1"
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "GPT-4.1"
        },
        "messages": {
          "values": [
            {
              "content": "=Analiza este documento y devu√©lveme un resumen jer√°rquico en JSON de su estructura. Para cada bloque, identifica:\n\n- `title`: t√≠tulo general del documento\n- `section`: secci√≥n principal\n- `subsection`: subt√≠tulo o parte espec√≠fica\n- `start`: √≠ndice del texto donde inicia esa secci√≥n\n- `end`: √≠ndice del texto donde termina\n\n_ Siempre debes arrancar por el primer caracter\nTexto completo:\n{{ $('Extract from File1').item.json.text }}\n"
            }
          ]
        },
        "jsonOutput": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        1040,
        160
      ],
      "id": "ec6bad83-fc7d-487e-aee8-a3b422e4bf8a",
      "name": "OpenAI",
      "credentials": {
        "openAiApi": {
          "id": "lid4f6Emqj7mGAPQ",
          "name": "OpenAi API Averis"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "GPT-4.1"
        },
        "messages": {
          "values": [
            {
              "content": "=Tienes la estructura de una base de conocimiento que contiene:\n\n- Un √∫nico t√≠tulo general.\n- Varias secciones y subsecciones.\n- Cada secci√≥n y subsecci√≥n tiene un rango de posiciones (`start`, `end`) que indican el lugar del texto completo donde aparecen.\n\nA continuaci√≥n, se te proporciona un fragmento de texto (`chunk`) con su √≠ndice de inicio (`startIndex`) respecto al texto original.\n\nTu tarea es: analizar el contenido del `chunk` y su posici√≥n (`startIndex`) y devolver exactamente a cu√°l secci√≥n y subsecci√≥n le corresponde, seg√∫n la estructura.\n\n‚úÖ Devuelve solo un JSON en este formato:\n\n{\n  \"title\": \"T√≠tulo exacto\",\n  \"section\": \"Nombre exacto de la secci√≥n\",\n  \"subsection\": \"Nombre exacto de la subsecci√≥n o null si no aplica\"\n}\n\n‚ùó Usa **los nombres exactos** que aparecen en la estructura. No inventes nuevos.\n\n---\n\nüìÑ Estructura (JSON):\n\n{{ $('OpenAI').item.json.message.content.toJsonString() }}\n\n---\n\nüß© Chunk:\n\n{{ $('Semantic Chunker').item.json.chunk }}\n\nüß≠ startIndex del chunk: {{ $('Semantic Chunker').item.json.startIndex }}\n"
            }
          ]
        },
        "jsonOutput": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        2200,
        240
      ],
      "id": "2eb3cf2b-5112-401b-9935-7ec77880017c",
      "name": "OpenAI1",
      "credentials": {
        "openAiApi": {
          "id": "lid4f6Emqj7mGAPQ",
          "name": "OpenAi API Averis"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// 1. Obtener todos los items de entrada desde el nodo anterior\nconst items = $input.all();\n\n// 2. Inicializar el array de salida\nconst outputItems = [];\n\n// 3. Procesar cada item\nfor (const item of items) {\n  try {\n    const inputJson = item.json;\n\n    // Asegurarse de que el campo input existe y tiene la estructura esperada\n    if (!inputJson || !inputJson.message || typeof inputJson.message.content !== 'string') {\n      throw new Error(\"La estructura 'message.content' no se encontr√≥ o no es un string.\");\n    }\n\n    // Parsear el contenido JSON de 'message.content'\n    const parsedContent = JSON.parse(inputJson.message.content);\n\n    // Obtener el valor original del campo 'chunk' (puede venir de un nodo anterior)\n    const originalChunk = inputJson.chunk !== undefined ? inputJson.chunk : null;\n\n    // Construir el nuevo objeto JSON de salida\n    const newOutputJson = {\n      ...parsedContent,\n      chunk: originalChunk\n    };\n\n    // A√±adirlo al array de salida\n    outputItems.push({ json: newOutputJson });\n\n  } catch (error) {\n    // Capturar errores y generar una salida de error clara\n    outputItems.push({\n      json: {\n        error: \"Fallo al procesar el item\",\n        details: error.message,\n        originalInput: item.json\n      }\n    });\n  }\n}\n\n// 4. Devolver todos los objetos transformados\nreturn outputItems;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2540,
        240
      ],
      "id": "1188ae67-4c0c-4267-b63c-cd30b840dd22",
      "name": "Code1"
    },
    {
      "parameters": {
        "jsCode": "// ‚úÖ 1) Funci√≥n para limpiar texto antes de enviarlo a la API\n// Esta funci√≥n se asegura de que el chunk no tenga s√≠mbolos extra√±os, comillas problem√°ticas o caracteres invisibles.\nconst cleanText = (text) => {\n  if (typeof text !== 'string') return ''; // Si no es un string, devolvemos vac√≠o\n\n  return text\n    .replace(/[\\n\\r\\t]+/g, ' ')             // Elimina saltos de l√≠nea, retornos y tabulaciones\n    .replace(/[\"\"¬´¬ª'']/g, ' ')              // Reemplaza comillas dobles, comillas angulares y simples\n    .replace(/[‚Äì‚Äî]/g, '-')                  // Reemplaza guiones largos por guiones normales\n    .replace(/[‚Ä¢¬∑]/g, '-')                  // Reemplaza bullets por guiones\n    .replace(/\\s{2,}/g, ' ')                // Reemplaza espacios m√∫ltiples por un solo espacio\n    .replace(/\\\\(?=[^\"\\\\/bfnrtu])|\\\\$/g, '')// Elimina barras invertidas inv√°lidas en JSON\n    .trim();                                // Quita espacios al principio y al final\n};\n\n// ‚úÖ 2) Recorremos cada item del flujo (cada chunk generado anteriormente)\nreturn items.map(item => {\n  // Obtenemos el chunk crudo desde el nodo anterior llamado \"Loop Over Items\"\n  const rawChunk = $node[\"Loop Over Items\"].json.chunk;\n\n  // ‚úÖ 3) Limpiamos el chunk usando la funci√≥n anterior\n  const cleaned = cleanText(rawChunk);\n\n  // ‚úÖ 4) Escapamos el texto para que sea v√°lido en JSON:\n  // - JSON.stringify escapa todo (comillas, saltos, etc.)\n  // - Luego le quitamos las comillas exteriores que JSON.stringify a√±ade al principio y final\n  const escaped = JSON.stringify(cleaned).slice(1, -1);\n\n  // ‚úÖ 5) Guardamos el texto limpio y escapado en el campo `chunk` del item actual\n  item.json.chunk = escaped;\n\n  // Devolvemos el item actualizado\n  return item;\n});\n\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2720,
        240
      ],
      "id": "6e82913d-615f-4515-8c61-575a1e32bad2",
      "name": "Code"
    },
    {
      "parameters": {
        "resource": "fileFolder",
        "returnAll": true,
        "filter": {
          "driveId": {
            "mode": "list",
            "value": "My Drive"
          },
          "folderId": {
            "__rl": true,
            "value": "1ndUYBSIKjWyF1MhXH_ibKRrWVZNOymEP",
            "mode": "list",
            "cachedResultName": "RAG Sem√°ntico",
            "cachedResultUrl": "https://drive.google.com/drive/folders/1ndUYBSIKjWyF1MhXH_ibKRrWVZNOymEP"
          }
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        320,
        160
      ],
      "id": "0207ee8b-c86b-47b7-99d2-7d3668d11909",
      "name": "Google Drive2",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "CmyDLQoxYdr0aKik",
          "name": "Google Daniel Averis"
        }
      }
    },
    {
      "parameters": {
        "operation": "pdf",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        1560,
        160
      ],
      "id": "cc191da4-c725-40d6-a11a-62fd97d02bfb",
      "name": "Extract from File"
    },
    {
      "parameters": {
        "operation": "download",
        "fileId": {
          "__rl": true,
          "value": "={{ $('Google Drive').item.json.id }}",
          "mode": "id"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        1380,
        160
      ],
      "id": "958c65d8-ae02-424e-a742-730dba474d56",
      "name": "Google Drive1",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "CmyDLQoxYdr0aKik",
          "name": "Google Daniel Averis"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "input",
              "value": "={{ $('Loop Over Items').item.json.chunk }}"
            },
            {
              "name": "model",
              "value": "text-embedding-3-small"
            },
            {
              "name": "encoding_format",
              "value": "float"
            },
            {
              "name": "dimensions",
              "value": "={{1536}}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2900,
        240
      ],
      "id": "8db12462-7894-4b7d-b6a5-c813251cc7e8",
      "name": "Tranformar embedding",
      "credentials": {
        "openAiApi": {
          "id": "lid4f6Emqj7mGAPQ",
          "name": "OpenAi API Averis"
        }
      }
    }
  ],
  "connections": {
    "Semantic Chunker": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request2": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "OpenAI1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‚ÄòTest workflow‚Äô": {
      "main": [
        [
          {
            "node": "Google Drive2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Drive": {
      "main": [
        [
          {
            "node": "Extract from File1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File1": {
      "main": [
        [
          {
            "node": "OpenAI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI": {
      "main": [
        [
          {
            "node": "Google Drive1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI1": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Tranformar embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Drive2": {
      "main": [
        [
          {
            "node": "Google Drive",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File": {
      "main": [
        [
          {
            "node": "Semantic Chunker",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Drive1": {
      "main": [
        [
          {
            "node": "Extract from File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Tranformar embedding": {
      "main": [
        [
          {
            "node": "HTTP Request2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {},
  "versionId": "12d87376-fd9f-4c0e-b326-f75f4e8fb656",
  "triggerCount": 0,
  "tags": []
}